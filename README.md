# 闲鱼监控机器人 (Goofish Monitor)

一个基于 **Playwright + FastAPI**
的闲鱼商品智能监控与采集系统，支持多任务调度、Web
管理界面、结果存储与查询，适合批量监控目标商品并进行后续数据分析。

------------------------------------------------------------------------

## 🖼️ 页面截图

### 1. 登录

<img width="1189" height="908" alt="image" src="https://github.com/user-attachments/assets/00df6b62-771a-4caa-8201-fa95ccc5153f" />

### 2. 主页

<img width="1189" height="894" alt="image" src="https://github.com/user-attachments/assets/31ab2ac3-ea93-44cc-b7e4-f20f0ac91422" />

------------------------------------------------------------------------

## 📂 项目结构

    .
    ├── src/
    │   ├── config.py           # 全局配置（登录状态文件路径、运行模式等）
    │   ├── spider/             # 页面解析逻辑
    │   │   ├── parsers.py      # 商品与卖家数据解析
    │   │   ├── spider.py       # 核心爬虫脚本，负责商品采集
    │   ├── task/
    │   │   ├── task.py         # 任务数据结构与管理
    │   │   ├── result.py       # 爬取结果存储与查询
    │   ├── server/
    │   │   ├── scheduler.py    # 任务调度与运行管理
    │   │   ├── server.py       # Web 服务入口，提供任务管理与结果接口
    │   ├── utils/
    │   │   ├── utils.py        # 工具函数 (sleep、数据获取安全封装等)
    ├── resources/
    │   └── static/             # 前端静态资源 (Web 管理界面)
    ├── tasks.json              # 任务配置文件
    ├── requirements.txt        # Python 依赖

------------------------------------------------------------------------

## ✨ 功能列表

-   [x] 多任务并行监控
-   [x] 支持关键词、价格区间、个人闲置等筛选条件
-   [x] 采集商品信息与卖家完整资料
-   [x] 爬虫过程自动防反爬处理与休眠机制
-   [x] FastAPI 提供任务与结果管理接口
-   [x] Web 管理界面支持任务管理与结果查看
-   [x] 提供 **Docker 镜像**，一键部署

------------------------------------------------------------------------

## 🚀 未来计划

-   [ ] 接入简单的 **AI 商品分析模块**（自动识别商品是否高风险/虚假）
-   [ ] 支持 **结果导出为 CSV/Excel**
-   [ ] 增加 **定时通知功能**（邮件/钉钉/微信推送）

-----------------------------------------------------------------------

## ⚡ 快速开始

### Docker 部署

#### 1. 环境准备

- [Docker Engine](https://docs.docker.com/engine/install/)

#### 2.拉取代码

```bash
git clone https://github.com/just-ads/ai-goofish.git
```

#### 3.创建.env 并运行容器

```bash
cd ai-goofish
# 创建.env
cp .env.example .env
# 构建并运行
docker-compose up --build -d
```

### 本地开发

#### 1. 环境准备

- [Python 3.10+](https://www.python.org/downloads/)

安装依赖：

``` bash
pip install -r requirements.txt
playwright install
```

#### 2. 构建前端资源

```bash
cd webui
npm run build
```

#### 3. 启动服务

``` bash
python start.py
```

启动后访问(默认用户名admin，密码admin123)：

    http://127.0.0.1:8000

登录后可在 Web 界面管理任务、启动/停止采集、查看数据。

------------------------------------------------------------------------

## 环境变量说明

| 变量名                 | 默认值 / 示例   | 说明                                     |
|---------------------|------------|----------------------------------------|
| **PCURL_TO_MOBILE** | `true`     | 是否开启电脑链接转换为手机链接                        |
| **RUN_HEADLESS**    | `true`     | 爬虫是否以无头模式运行 (true/false)，本地调试可设为 false |
| **ENABLE_THINKING** | `false`    | 是否启用 `enable_thinking` 参数，部分模型需要       |
| **SERVER_PORT**     | `8000`     | 服务运行端口，默认 8000                         |
| **WEB_USERNAME**    | `admin`    | Web 服务登录用户名                            |
| **WEB_PASSWORD**    | `admin123` | Web 服务登录密码                             |

------------------------------------------------------------------------

## 🔄 工作流程

1. **任务配置加载**
    - 从 `tasks.json` 读取启用的任务（或根据传参执行单任务）。
    - 每个任务包含关键词、页数、价格区间等筛选条件。
2. **爬虫执行**
    - 使用 Playwright
      打开搜索页，模拟用户筛选条件（最新、个人闲置、价格区间）。
    - 解析搜索结果，获取商品 ID 与链接。
    - 请求详情页，采集商品信息与卖家信息。
    - 自动检测反爬虫机制，如遇拦截会进入长时间休眠并退出。
3. **结果存储**
    - 每个任务的结果以 `jsonl` 格式保存，避免重复写入。
    - 提供基于关键词的结果查询与删除接口。
4. **Web 管理界面**
    - 登录认证基于 JWT。
    - 提供任务的增删改查、手动启动/停止、查看执行状态。
    - 结果支持分页查询与筛选。

------------------------------------------------------------------------

## 💖 鸣谢

本项目在开发过程中参考了以下项目：

- [ai-goofish-monitor](https://github.com/dingyufei615/ai-goofish-monitor)